{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OBmC3UmYaRP"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVCytM2-YWWR"
   },
   "source": [
    "https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c5L6dnEoy51r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://truwl-pypicloud-admin:****@pypi.truwl.com/simple/\n",
      "Requirement already satisfied: torch in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from torch) (3.10.0.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://truwl-pypicloud-admin:****@pypi.truwl.com/simple/\n",
      "Requirement already satisfied: torchtext in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: tqdm in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from torchtext) (4.62.3)\n",
      "Requirement already satisfied: torch==1.10.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from torchtext) (1.10.0)\n",
      "Requirement already satisfied: numpy in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from torchtext) (1.21.4)\n",
      "Requirement already satisfied: requests in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from torchtext) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from requests->torchtext) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from requests->torchtext) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from requests->torchtext) (3.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://truwl-pypicloud-admin:****@pypi.truwl.com/simple/\n",
      "Requirement already satisfied: seaborn in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from seaborn) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://truwl-pypicloud-admin:****@pypi.truwl.com/simple/\n",
      "Requirement already satisfied: ipywidgets in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (7.6.5)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipywidgets) (7.29.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipywidgets) (6.5.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: appnope in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: pickleshare in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.22)\n",
      "Requirement already satisfied: pygments in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: backcall in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (58.5.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: decorator in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.2.1)\n",
      "Requirement already satisfied: jupyter-core in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: argon2-cffi in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: jinja2 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: nbconvert in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.5)\n",
      "Requirement already satisfied: testpath in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: bleach in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pycparser in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: webencodings in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Users/leipzig/.virtualenvs/bestguess/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchtext\n",
    "!pip install seaborn\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGQpFos2EZCB",
    "outputId": "0bdbdd40-52f2-4121-8b37-7b3ff07d7da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  6390  100  6390    0     0  29346      0 --:--:-- --:--:-- --:--:-- 29447\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  7697  100  7697    0     0  21842      0 --:--:-- --:--:-- --:--:-- 21804\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 38523  100 38523    0     0   126k      0 --:--:-- --:--:-- --:--:--  126k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 43259  100 43259    0     0   138k      0 --:--:-- --:--:-- --:--:--  138k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4637  100  4637    0     0  19036      0 --:--:-- --:--:-- --:--:-- 19082\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8521  100  8521    0     0  14657      0 --:--:-- --:--:-- --:--:-- 14640\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10535  100 10535    0     0  42304      0 --:--:-- --:--:-- --:--:-- 42479\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/truwl/capanno/biowdl-structs/workflows/biowdl/RNA-seq/0.1.0/rnaseq_inputs-metadata.yaml > rnaseq.yaml\n",
    "!curl https://raw.githubusercontent.com/truwl/capanno/master/workflows/Broad/WholeGenomeGermlineSingleSample/v2.3.1/wgs_inputs-metadata.yaml > wgs.yaml\n",
    "!curl https://raw.githubusercontent.com/truwl/capanno/master/workflows/ENCODE-DCC/atac-seq-pipeline/v1.9.0/atac-inputs-metadata.yaml > atac.yaml\n",
    "!curl https://raw.githubusercontent.com/truwl/capanno/master/workflows/ENCODE-DCC/chip-seq-pipeline2/v1.6.0/chip-inputs-metadata.yaml > chip.yaml\n",
    "!curl https://raw.githubusercontent.com/truwl/capanno/master/workflows/ENCODE-DCC/mirna-seq-pipeline/v1.2.0/mirna_seq_pipeline-inputs-metadata.yaml > mirna.yaml\n",
    "!curl https://raw.githubusercontent.com/truwl/capanno/gatk-sv/workflows/Broad/gatk-sv-ss/v0.18.2-beta/inputs-metadata.yaml > sv.yaml\n",
    "!curl https://raw.githubusercontent.com/truwl/capanno/master/workflows/variant/benchmarking/0.2/inputs-metadata.yaml > vb.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyZ65LZ8YgtG"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bY4NR2cVZNFA",
    "outputId": "21546d96-0072-4e25-dc61-b628169ef094"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "dl7rqQ4uZPiv"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "# Preliminaries\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDBAx2Q-ZMl7",
    "outputId": "ac527847-9239-4f7c-aac0-bd2904e13bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqOJAYCiYlZs"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "RV5TMDTbMPtF",
    "outputId": "5c8a67d2-f62c-449b-e15b-aaedc55097c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputfield</th>\n",
       "      <th>desc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sampleConfigFile</td>\n",
       "      <td>The sample configuration file</td>\n",
       "      <td>required_inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dockerImagesFile</td>\n",
       "      <td>A file listing the used docker images</td>\n",
       "      <td>required_inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>starIndex</td>\n",
       "      <td>A list of star index files</td>\n",
       "      <td>required_inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>referenceFasta</td>\n",
       "      <td>A path to a reference fasta</td>\n",
       "      <td>required_inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referenceFastaFai</td>\n",
       "      <td>The path to the index associated with the refe...</td>\n",
       "      <td>required_inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mpRegionsPath</td>\n",
       "      <td></td>\n",
       "      <td>Paths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>odRegionsPath</td>\n",
       "      <td></td>\n",
       "      <td>Paths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sdRegionsPath</td>\n",
       "      <td></td>\n",
       "      <td>Paths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>unRegionsPath</td>\n",
       "      <td></td>\n",
       "      <td>Paths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>competitors</td>\n",
       "      <td></td>\n",
       "      <td>CachedMetrics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           inputfield                                               desc  \\\n",
       "0    sampleConfigFile                      The sample configuration file   \n",
       "1    dockerImagesFile              A file listing the used docker images   \n",
       "2           starIndex                         A list of star index files   \n",
       "3      referenceFasta                        A path to a reference fasta   \n",
       "4   referenceFastaFai  The path to the index associated with the refe...   \n",
       "..                ...                                                ...   \n",
       "51      mpRegionsPath                                                      \n",
       "52      odRegionsPath                                                      \n",
       "53      sdRegionsPath                                                      \n",
       "54      unRegionsPath                                                      \n",
       "55        competitors                                                      \n",
       "\n",
       "              label  \n",
       "0   required_inputs  \n",
       "1   required_inputs  \n",
       "2   required_inputs  \n",
       "3   required_inputs  \n",
       "4   required_inputs  \n",
       "..              ...  \n",
       "51            Paths  \n",
       "52            Paths  \n",
       "53            Paths  \n",
       "54            Paths  \n",
       "55    CachedMetrics  \n",
       "\n",
       "[504 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def runitodf(runitpath):\n",
    "  with open(runitpath) as metaf:\n",
    "    meta=yaml.load(metaf,Loader=yaml.Loader)\n",
    "    metakeys = meta['parameter_meta']\n",
    "    df = pd.DataFrame(columns=['inputfield','desc','label'])\n",
    "    for k in metakeys:\n",
    "      df = df.append({\n",
    "      \"inputfield\": k,\n",
    "      \"desc\": metakeys[k].get('description',''),\n",
    "      \"label\": metakeys[k]['group']\n",
    "        }, ignore_index=True)\n",
    "    return(df)\n",
    "\n",
    "df=runitodf(\"rnaseq.yaml\")\n",
    "for f in ['wgs','atac','chip','mirna','sv','vb']:\n",
    "    df=df.append(runitodf(\"{0}.yaml\".format(f)))\n",
    "\n",
    "df['inputfield']=df['inputfield'].str.split('.').str[1:].str.join(sep='')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "fF1DCVrCh6_d"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "fdGccqrAZYjw",
    "outputId": "85184ff2-f435-4e7d-d08f-96fafa50b9fd"
   },
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "MAX_SEQ_LEN = 255\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "import numpy as np\n",
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "fields = [('label', label_field), ('desc', text_field),('inputfield',text_field)]\n",
    "# TabularDataset\n",
    "\n",
    "#https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test\n",
    "def train_validate_test_split(df, train_percent=.4, validate_percent=.4, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "\n",
    "traindf, validatedf, testdf = train_validate_test_split(df)\n",
    "traindf.to_csv(path_or_buf=\"train.csv\", sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', line_terminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict')\n",
    "validatedf.to_csv(path_or_buf=\"validate.csv\", sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', line_terminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict')\n",
    "testdf.to_csv(path_or_buf=\"test.csv\", sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', line_terminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict')\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=\".\", train='train.csv', validation='validate.csv',\n",
    "                                           test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
    "# Iterators\n",
    "train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.inputfield),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.inputfield),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=16, device=device, train=False, shuffle=False, sort=False)\n",
    "assert(set(validatedf['label']).issubset(set(traindf['label'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IX-lWIMaYnsA"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "2RkcXCHSph1_"
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z81slSELYqO1"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "JRpTJUGhklDv"
   },
   "outputs": [],
   "source": [
    "# Save and Load Functions\n",
    "\n",
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):\n",
    "    \n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "81w1lahhkozO"
   },
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = \".\",\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (labels, inputfield, desc), _ in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)           \n",
    "            labels = labels.to(device)\n",
    "            desc = desc.type(torch.LongTensor)  \n",
    "            desc = desc.to(device)\n",
    "            inputfield = inputfield.type(torch.LongTensor)  \n",
    "            inputfield = inputfield.to(device)\n",
    "            output = model(desc, inputfield, labels)\n",
    "            loss, _ = output\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "\n",
    "                    # validation loop\n",
    "                    for (labels, inputfield, desc), _ in valid_loader:\n",
    "                        labels = labels.type(torch.LongTensor)           \n",
    "                        labels = labels.to(device)\n",
    "                        desc = desc.type(torch.LongTensor)  \n",
    "                        desc = desc.to(device)\n",
    "                        inputfield = inputfield.type(torch.LongTensor)  \n",
    "                        inputfield = inputfield.to(device)\n",
    "                        output = model(desc, inputfield, labels)\n",
    "                        loss, _ = output\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
    "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "nHdi_cyEvC9K",
    "outputId": "11756896-1c4c-4083-ddc9-aa0e3dad2184"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b3/pgs49r2x3flcsw92j5yzcbh00000gp/T/ipykernel_31672/282395632.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/b3/pgs49r2x3flcsw92j5yzcbh00000gp/T/ipykernel_31672/1933594829.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader, valid_loader, num_epochs, eval_every, file_path, best_valid_loss)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0minputfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0minputfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bestguess/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "train(model=model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6N1dBUZK5WCG"
   },
   "outputs": [],
   "source": [
    "BERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JaIsEttvMeO"
   },
   "outputs": [],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qLyO8EWwJEo"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFBhAW6rwKly"
   },
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, title, text, titletext), _ in test_loader:\n",
    "\n",
    "                labels = labels.type(torch.LongTensor)           \n",
    "                labels = labels.to(device)\n",
    "                titletext = titletext.type(torch.LongTensor)  \n",
    "                titletext = titletext.to(device)\n",
    "                output = model(titletext, labels)\n",
    "\n",
    "                _, output = output\n",
    "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLlijSLcxv2j"
   },
   "outputs": [],
   "source": [
    "best_model = BERT().to(device)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model)\n",
    "\n",
    "evaluate(best_model, test_iter)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classifywithBert",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
